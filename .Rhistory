#              api_secret="kJ1P1T320JWvYsXUzp1wT8VbrAMytLLEpY0XMg1bA2VzBVL4G1",
#              access_token="1030168029466972160-mvTuwu6R3vUHEmVe39WgqBZchl2l0k",
#              access_token_secret="o26V3KmhiNDws0GBOkkdt3m7yUGigq3tOCaOHMlbkc9PX")
library(devtools)
library(twitteR)
api_key <- "uPLeaTyxmrR5FwpUWf4d3GUG7"
api_secret <- "loeVZowUat6eQTJmhspy7L5Lz5It0YIPpH60Dc6Z3uaVkLomSu"
access_token <- "1030168029466972160-8KpxSXyIADB4TJQJ2qGc0OmYpVuvGu"
access_token_secret <- "n9Wl9dcpI4rpFM7xINBsY9SOuUC7SkYXq18mWTz6oZxGU"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
# searchTwitter("iphone",n=150)
# create_token(app="SentimentAnalysisx001",
#              api_key="lJlRZRqb4CSMgfeC5WcSaCsBo",
#              api_secret="kJ1P1T320JWvYsXUzp1wT8VbrAMytLLEpY0XMg1bA2VzBVL4G1",
#              access_token="1030168029466972160-mvTuwu6R3vUHEmVe39WgqBZchl2l0k",
#              access_token_secret="o26V3KmhiNDws0GBOkkdt3m7yUGigq3tOCaOHMlbkc9PX")
library(devtools)
library(twitteR)
api_key <- "uPLeaTyxmrR5FwpUWf4d3GUG7"
api_secret <- "loeVZowUat6eQTJmhspy7L5Lz5It0YIPpH60Dc6Z3uaVkLomSu"
access_token <- "1030168029466972160-8KpxSXyIADB4TJQJ2qGc0OmYpVuvGu"
access_token_secret <- "n9Wl9dcpI4rpFM7xINBsY9SOuUC7SkYXq18mWTz6oZxGU"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
searchTwitter("iphone",n=150)
#extract tweets
GST.tweets = searchTwitter("GST",n=1500)
#convert into dataframe
data<-do.call("rbind",lapply(GST.tweets,as.data.frame))
#remove odds and emoticons
data$text<-sapply(data$text,function(row)iconv(row,"latin1","ASCII", sub = ""))
#remove url
data$text<-gsub("(f|ht)tp(s?)://(.*)[.][a-z]+","",data$text)
sample<-data$text
View(GST.tweets)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
}
GST_text = sapply(GST.tweets, function(x) x$getText()) #sapply returns a vector
data<- do.call("rbind", lapply(GST.tweets, as.data.frame)) #lapply returns a list
GST_text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
str(GST_text) #gives the summary/internal structure of an R object
library(tm) #tm: text mining
GST_corpus <- Corpus(VectorSource(GST_text)) #corpus is a collection of text documents
GST_corpus
inspect(GST_corpus[1])
#clean text
library(wordcloud)
GST_clean <- tm_map(GST_corpus, removePunctuation)
GST_clean <- tm_map(GST_clean, removeWords, stopwords("english"))
GST_clean <- tm_map(GST_clean, removeNumbers)
GST_clean <- tm_map(GST_clean, stripWhitespace)
wordcloud(GST_clean, random.order=F,max.words=80, col=rainbow(50), scale=c(3.5,1))
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
}
# create_token(app="SentimentAnalysisx001",
#              api_key="lJlRZRqb4CSMgfeC5WcSaCsBo",
#              api_secret="kJ1P1T320JWvYsXUzp1wT8VbrAMytLLEpY0XMg1bA2VzBVL4G1",
#              access_token="1030168029466972160-mvTuwu6R3vUHEmVe39WgqBZchl2l0k",
#              access_token_secret="o26V3KmhiNDws0GBOkkdt3m7yUGigq3tOCaOHMlbkc9PX")
library(devtools)
library(twitteR)
api_key <- "uPLeaTyxmrR5FwpUWf4d3GUG7"
api_secret <- "loeVZowUat6eQTJmhspy7L5Lz5It0YIPpH60Dc6Z3uaVkLomSu"
access_token <- "1030168029466972160-8KpxSXyIADB4TJQJ2qGc0OmYpVuvGu"
access_token_secret <- "n9Wl9dcpI4rpFM7xINBsY9SOuUC7SkYXq18mWTz6oZxGU"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
searchTwitter("GST",n=150)
#extract tweets
GST.tweets = searchTwitter("GST",n=1500)
#convert into dataframe
data<-do.call("rbind",lapply(GST.tweets,as.data.frame))
#remove odds and emoticons
data$text<-sapply(data$text,function(row)iconv(row,"latin1","ASCII", sub = ""))
#remove url
data$text<-gsub("(f|ht)tp(s?)://(.*)[.][a-z]+","",data$text)
sample<-data$text
View(data)
# Clean the tweets and returns merged data frame
result = score.sentiment(sample, pos.words, neg.words)
library(reshape)
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Score=table1$value, Positive=table2$value, Negative=table3$value)
install.packages("reshape")
# Clean the tweets and returns merged data frame
result = score.sentiment(sample, pos.words, neg.words)
library(reshape)
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Score=table1$value, Positive=table2$value, Negative=table3$value)
View(data)
# Clean the tweets and returns merged data frame
library(reshape)
result = score.sentiment(sample, pos.words, neg.words)
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Score=table1$value, Positive=table2$value, Negative=table3$value)
save
save(data)
save("data")
save.image(data)
# Clean the tweets and returns merged data frame
library(reshape)
result = score.sentiment(sample, pos.words, neg.words)
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Score=table1$value, Positive=table2$value, Negative=table3$value)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
}
# Clean the tweets and returns merged data frame
result = score.sentiment(sample, pos.words, neg.words)
library(reshape)
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Score=table1$value, Positive=table2$value, Negative=table3$value)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
}
result = score.sentiment(sample, pos.words, neg.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
result = score.sentiment(sample, pos.words, neg.words)
}
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
}
result = score.sentiment(sample, pos.words, neg.words)
#adding positive and negative words.txt files
pos.words=scan("positive-words.txt",what = 'character',comment.char = ';')
neg.words=scan("negative-words.txt",what = 'character',comment.char = ';')
#adding more words that people use
pos.words=c(pos.words, 'Congrats', 'prizes', 'prize', 'thanks', 'thnx', 'Grt', 'gr8', 'plz', 'trending', 'recovering', 'brainstorm', 'leader')
neg.words = c(neg.words, 'Fight', 'fighting', 'wtf', 'arrest', 'no', 'not')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
}
# Clean the tweets and returns merged data frame
result = score.sentiment(sample, pos.words, neg.words)
library(reshape)
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Score=table1$value, Positive=table2$value, Negative=table3$value)
View(data)
View(table_final)
GST_text = sapply(GST.tweets, function(x) x$getText()) #sapply returns a vector
data<- do.call("rbind", lapply(GST.tweets, as.data.frame)) #lapply returns a list
GST_text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
str(GST_text) #gives the summary/internal structure of an R object
library(tm) #tm: text mining
GST_corpus <- Corpus(VectorSource(GST_text)) #corpus is a collection of text documents
GST_corpus
inspect(GST_corpus[1])
#clean text
library(wordcloud)
GST_clean <- tm_map(GST_corpus, removePunctuation)
GST_clean <- tm_map(GST_clean, removeWords, stopwords("english"))
GST_clean <- tm_map(GST_clean, removeNumbers)
GST_clean <- tm_map(GST_clean, stripWhitespace)
wordcloud(GST_clean, random.order=F,max.words=80, col=rainbow(50), scale=c(3.5,1))
install.packages("wordcloud")
install.packages("tm")
GST_text = sapply(GST.tweets, function(x) x$getText()) #sapply returns a vector
data<- do.call("rbind", lapply(GST.tweets, as.data.frame)) #lapply returns a list
GST_text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
str(GST_text) #gives the summary/internal structure of an R object
library(tm) #tm: text mining
GST_corpus <- Corpus(VectorSource(GST_text)) #corpus is a collection of text documents
GST_corpus
inspect(GST_corpus[1])
#clean text
library(wordcloud)
GST_clean <- tm_map(GST_corpus, removePunctuation)
GST_clean <- tm_map(GST_clean, removeWords, stopwords("english"))
GST_clean <- tm_map(GST_clean, removeNumbers)
GST_clean <- tm_map(GST_clean, stripWhitespace)
wordcloud(GST_clean, random.order=F,max.words=80, col=rainbow(50), scale=c(3.5,1))
View(GST_clean)
View(table_final)
write.table(table_final, file = "Attempt1.csv", sep = ",")
#extract tweets
GST.tweets = searchTwitter("GST",n=100000)
